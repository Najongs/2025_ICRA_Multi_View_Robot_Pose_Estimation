import os
import glob
import json
import cv2
import numpy as np
import configparser
import pandas as pd
import matplotlib.pyplot as plt
from collections import defaultdict
from scipy.spatial.transform import Rotation as R

# =================================================================================
# âš™ï¸ í†µí•© ì„¤ì • (Global Configuration)
# =================================================================================

# --- ì…ë ¥ ê²½ë¡œ ---
RAW_DATA_DIRS = [
    "./Meca_insertion/Meca_ArUco/ArUco_cap_250514",
    "./Meca_insertion/Meca_ArUco/ArUco_cap2_250514",
    "./Meca_insertion/Meca_ArUco/ArUco_cap3_250514"
]
ZED_CONF_DIR = "./All_camera_conf"
IMAGE_DIR = "./Meca_insertion/Meca_ArUco/ArUco_cap_250514"

# --- ì¶œë ¥ ê²½ë¡œ ---
CALIB_DIR = "./Meca_insertion/Meca_calib_cam_from_conf"
CORRECTED_ARUCO_DIR = "./Meca_insertion/Meca_correct_ArUco" # ë³´ì •ëœ ArUco ë°ì´í„° ì €ì¥ ê²½ë¡œ
RESULT_IMAGE_DIR = "./Meca_insertion/Meca_calib_results_images"
FINAL_SUMMARY_OUTPUT_PATH = "./Meca_insertion/aruco_final_summary.json"

# --- íŒŒë¼ë¯¸í„° ---
MARKER_REAL_SIZE_M = 0.05  # ë§ˆì»¤ì˜ ì‹¤ì œ í•œ ë³€ ê¸¸ì´ (ë¯¸í„°)

# --- ì¹´ë©”ë¼ ë° ë·° ì„¤ì • ---
CAMERA_SERIALS = {41182735: "front", 49429257: "right", 44377151: "left", 49045152: "top"}
# [ìˆ˜ì •] view ì´ë¦„ìœ¼ë¡œ serialì„ ì°¾ê¸° ìœ„í•œ ì—­ë°©í–¥ ë”•ì…”ë„ˆë¦¬ ìƒì„±
VIEW_TO_SERIAL = {v: k for k, v in CAMERA_SERIALS.items()}
VIEWS = ['front', 'left', 'right', 'top']
CAMS = ['leftcam', 'rightcam']


# --- ë§ˆì»¤ ì˜¤í”„ì…‹ ì„¤ì • ---
MARKER_OFFSETS = {
    "front": {"1": [-0.100, 0.125, 0.0065], "2": [-0.100, 0.025, 0.0065], "3": [0, -0.175, 0.0065], "4": [-0.100, -0.075, 0.0065], "5": [0.125, 0.025, 0.0065], "6": [0.125, 0.125, 0.0065], "7": [0, -0.075, 0.0065], "8": [0.125, -0.075, 0.0065]},
    "left": {"3": [0, -0.175, 0.0065], "4": [-0.100, -0.075, 0.0065], "5": [0.125, 0.025, 0.0065], "6": [0.125, 0.125, 0.0065], "7": [0.000, -0.075, 0.0065], "8": [0.125, -0.075, 0.0065]},
    "right": {"1": [-0.100, 0.125, 0.0065], "2": [-0.100, 0.025, 0.0065], "3": [0.000, -0.175, 0.0065], "4": [-0.100, -0.075, 0.0065], "7": [0.000, -0.075, 0.0065], "8": [0.125, -0.075, 0.0065]},
    "top": {"1": [-0.100, 0.125, 0.0065], "2": [-0.100, 0.025, 0.0065], "3": [0, -0.175, 0.0065], "4": [-0.100, -0.075, 0.0065], "5": [0.125, 0.025, 0.0065], "6": [0.125, 0.125, 0.0065], "7": [0, -0.075, 0.0065], "8": [0.125, -0.075, 0.0065]},
}
for view, markers in MARKER_OFFSETS.items():
    for mid, offset in markers.items():
        MARKER_OFFSETS[view][mid] = np.array(offset)

# =================================================================================
# í—¬í¼ í•¨ìˆ˜ (Helper Functions)
# =================================================================================
def parse_filename(filename):
    parts = filename.split('_'); return parts[0], parts[2]

def average_quaternion(quaternions):
    if len(quaternions) == 0: return np.array([0, 0, 0, 1])
    # Scipyì˜ í‰ê·  ê³„ì‚° ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ ë” ì•ˆì •ì ì´ê³  ê°„ê²°í•˜ê²Œ ì²˜ë¦¬
    return R.from_quat(quaternions).mean().as_quat()

def average_position(positions):
    if len(positions) == 0: return np.array([0, 0, 0])
    return np.mean(positions, axis=0)

def remove_outliers(positions, quaternions, pos_thresh=0.005, rot_thresh_deg=5.0):
    if len(positions) < 3: return positions, quaternions, np.ones(len(positions), dtype=bool)
    
    avg_pos = average_position(positions)
    avg_quat_R = R.from_quat(average_quaternion(quaternions))
    
    pos_dists = np.linalg.norm(positions - avg_pos, axis=1)
    # ìœ„ì¹˜ ì´ìƒì¹˜ ì œê±° (ì¤‘ìœ„ê°’ ê¸°ì¤€)
    median_pos_dist = np.median(pos_dists)
    pos_mask = pos_dists < median_pos_dist + pos_thresh
    
    rot_dists_deg = np.array([np.rad2deg((avg_quat_R.inv() * R.from_quat(q)).magnitude()) for q in quaternions])
    # íšŒì „ ì´ìƒì¹˜ ì œê±° (ì¤‘ìœ„ê°’ ê¸°ì¤€)
    median_rot_dist = np.median(rot_dists_deg)
    rot_mask = rot_dists_deg < median_rot_dist + rot_thresh_deg

    valid_mask = pos_mask & rot_mask
    return positions[valid_mask], quaternions[valid_mask], valid_mask

# =================================================================================
# ğŸ“œ ë©”ì¸ ê¸°ëŠ¥ í•¨ìˆ˜ (Main Function Blocks)
# =================================================================================

def extract_camera_calibration():
    """ZED ì¹´ë©”ë¼ì˜ .conf íŒŒì¼ì—ì„œ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    print("--- ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì¶”ì¶œ ì‹œì‘ ---")
    os.makedirs(CALIB_DIR, exist_ok=True)
    for serial, position in CAMERA_SERIALS.items():
        conf_path = os.path.join(ZED_CONF_DIR, f"SN{serial}.conf")
        if not os.path.exists(conf_path):
            print(f"ê²½ê³ : [{position}] ì„¤ì • íŒŒì¼ ì—†ìŒ: {conf_path}")
            continue
        for side, side_name in [("LEFT", "leftcam"), ("RIGHT", "rightcam")]:
            try:
                config = configparser.ConfigParser()
                # utf-8-sigë¡œ BOM(Byte Order Mark) ë¬¸ì œ í•´ê²°
                with open(conf_path, "r", encoding="utf-8-sig") as f: config.read_file(f)
                
                # ZED X One ì¹´ë©”ë¼ëŠ” FHD1200, ZED 2i ì¹´ë©”ë¼ëŠ” FHD í•´ìƒë„ ì‚¬ìš© ê°€ëŠ¥
                section = f"{side.upper()}_CAM_FHD1200"
                
                cam = config[section]
                data = {
                    "camera_matrix": [[float(cam["fx"]), 0.0, float(cam["cx"])], [0.0, float(cam["fy"]), float(cam["cy"])], [0.0, 0.0, 1.0]],
                    "distortion_coeffs": [float(cam[k]) for k in ["k1", "k2", "p1", "p2", "k3"]]
                }
                filename = f"{position}_{serial}_{side_name}_calib.json"
                with open(os.path.join(CALIB_DIR, filename), "w") as f: json.dump(data, f, indent=4)
                print(f"[{position}/{side_name}] ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì €ì¥ ì™„ë£Œ.")
            except Exception as e:
                print(f"ì˜¤ë¥˜: [{position}] {side_name} ì²˜ë¦¬ ì¤‘ - {e}")
    print("--- ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì¶”ì¶œ ì™„ë£Œ ---\n")

def stage1_average_raw_data():
    """1ë‹¨ê³„: ì—¬ëŸ¬ Raw ë°ì´í„°ì—ì„œ ì´ìƒì¹˜ë¥¼ ì œê±°í•˜ê³  í‰ê·  í¬ì¦ˆì™€ ì½”ë„ˆë¥¼ ê³„ì‚°í•˜ì—¬ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    print("--- STAGE 1: ì›ë³¸ ë°ì´í„° í‰ê·  ê³„ì‚° ë° ì´ìƒì¹˜ ì œê±° ì‹œì‘ ---")
    # [ìˆ˜ì •] ìš”ì²­í•˜ì‹ ëŒ€ë¡œ ì¶œë ¥ ê²½ë¡œ ìƒì„± ë¡œì§ ì¶”ê°€
    os.makedirs(CORRECTED_ARUCO_DIR, exist_ok=True)
    
    raw_data = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))
    for base_dir in RAW_DATA_DIRS:
        for fname in glob.glob(os.path.join(base_dir, "*.json")):
            view, cam = parse_filename(os.path.basename(fname))
            with open(fname, 'r') as f:
                content = json.load(f)
                for mid, mdata in content.items():
                    if "corners_pixel" in mdata: raw_data[view][cam][mid].append(mdata)

    corrected_data_stage1 = defaultdict(lambda: defaultdict(dict))
    for view, cams_data in raw_data.items():
        for cam, markers_data in cams_data.items():
            for mid, entries in markers_data.items():
                if len(entries) < 2:
                    corrected_data_stage1[view][cam][mid] = entries[0]
                    continue
                
                pos = np.array([[m['position_m'][k] for k in 'xyz'] for m in entries])
                quat = np.array([[m['rotation_quat'][k] for k in 'xyzw'] for m in entries])
                corners = np.array([m['corners_pixel'] for m in entries], dtype=np.float32)
                
                pos_f, quat_f, mask = remove_outliers(pos, quat)
                if len(pos_f) == 0 or len(pos_f) < len(entries) / 3: # í•„í„°ë§ í›„ ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì œì™¸
                    print(f"ê²½ê³ : ë§ˆì»¤ {mid} ({view}_{cam}) ë°ì´í„°ê°€ ë¶ˆì•ˆì •í•˜ì—¬ ì œì™¸ë©ë‹ˆë‹¤. (ì›ë³¸ {len(entries)}ê°œ -> í•„í„°ë§ í›„ {len(pos_f)}ê°œ)")
                    continue
                
                corrected_data_stage1[view][cam][mid] = {
                    "position_m": {k: float(v) for k, v in zip('xyz', average_position(pos_f))},
                    "rotation_quat": {k: float(v) for k, v in zip('xyzw', average_quaternion(quat_f))},
                    "corners_pixel": np.mean(corners[mask], axis=0).tolist()
                }
            
            # [ìˆ˜ì •] ìš”ì²­í•˜ì‹ ëŒ€ë¡œ ë³´ì •ëœ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” ë¡œì§ ì¶”ê°€
            if corrected_data_stage1[view][cam]:
                output_path = os.path.join(CORRECTED_ARUCO_DIR, f"{view}_{cam}_corrected.json")
                with open(output_path, 'w') as f:
                    json.dump(corrected_data_stage1[view][cam], f, indent=4)
                print(f"ë³´ì •ëœ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {output_path}")

    print("--- STAGE 1 ì™„ë£Œ ---\n")
    return corrected_data_stage1

def stage2_recalculate_pose_from_corners(stage1_data):
    """2ë‹¨ê³„: 1ë‹¨ê³„ì˜ í‰ê·  ì½”ë„ˆ ì¢Œí‘œë¥¼ ì´ìš©í•´ solvePnPë¡œ í¬ì¦ˆë¥¼ ì •ë°€í•˜ê²Œ ì¬ê³„ì‚°í•©ë‹ˆë‹¤."""
    print("--- STAGE 2: ì½”ë„ˆ ì¢Œí‘œ ê¸°ë°˜ í¬ì¦ˆ ì¬ê³„ì‚° ì‹œì‘ ---")
    marker_3d_pts = np.array([[-1, 1, 0], [1, 1, 0], [1, -1, 0], [-1, -1, 0]], dtype=np.float32) * MARKER_REAL_SIZE_M / 2
    recalculated_data = defaultdict(lambda: defaultdict(dict))
    
    for view, cams_data in stage1_data.items():
        for cam, markers_data in cams_data.items():
            # [ìˆ˜ì •] VIEW_TO_SERIALì„ ì‚¬ìš©í•˜ì—¬ view ì´ë¦„ìœ¼ë¡œ serial ë²ˆí˜¸ë¥¼ ì°¾ìŒ
            serial = VIEW_TO_SERIAL.get(view)
            if not serial:
                print(f"ê²½ê³ : {view}ì— í•´ë‹¹í•˜ëŠ” serial ë²ˆí˜¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            calib_path = os.path.join(CALIB_DIR, f"{view}_{serial}_{cam}_calib.json")
            if not os.path.exists(calib_path):
                print(f"ê²½ê³ : ìº˜ë¦¬ë¸Œë ˆì´ì…˜ íŒŒì¼ ì—†ìŒ: {calib_path}")
                continue
            
            with open(calib_path) as f: calib = json.load(f)
            K, dist = np.array(calib["camera_matrix"]), np.array(calib["distortion_coeffs"])
            
            for mid, data in markers_data.items():
                corners = np.array(data["corners_pixel"], dtype=np.float32)
                ret, rvec, tvec = cv2.solvePnP(marker_3d_pts, corners, K, dist)
                if not ret: continue
                
                # Levenberg-Marquardt ìµœì í™”ë¥¼ ì‚¬ìš©í•˜ì—¬ í¬ì¦ˆ ì •ë°€ë„ í–¥ìƒ
                rvec, tvec = cv2.solvePnPRefineLM(marker_3d_pts, corners, K, dist, rvec, tvec)
                
                quat = R.from_rotvec(rvec.flatten()).as_quat()
                recalculated_data[view][cam][mid] = {
                    "position_m": {k: float(v) for k, v in zip('xyz', tvec.flatten())},
                    "rotation_quat": {k: float(v) for k, v in zip('xyzw', quat)},
                }
    print("--- STAGE 2 ì™„ë£Œ ---\n")
    return recalculated_data

def stage3_visualize_and_summarize(stage2_data):
    """3ë‹¨ê³„: ìµœì¢… ì˜¤í”„ì…‹ ì ìš©, ì‹œê°í™” ë° ìš”ì•½."""
    print("--- STAGE 3: ìµœì¢… ì˜¤í”„ì…‹ ì ìš©, ì‹œê°í™” ë° ìš”ì•½ ì‹œì‘ ---")
    os.makedirs(RESULT_IMAGE_DIR, exist_ok=True)
    final_summary = []
    
    for view in VIEWS:
        for cam in CAMS:
            poses = stage2_data.get(view, {}).get(cam)
            if not poses: continue
            
            # [ìˆ˜ì •] VIEW_TO_SERIALì„ ì‚¬ìš©í•˜ì—¬ view ì´ë¦„ìœ¼ë¡œ serial ë²ˆí˜¸ë¥¼ ì°¾ìŒ
            serial = VIEW_TO_SERIAL.get(view)
            if not serial: continue
            
            calib_path = os.path.join(CALIB_DIR, f"{view}_{serial}_{cam}_calib.json")
            img_paths = glob.glob(os.path.join(IMAGE_DIR, f"{view}_*_{cam}_*.png"))
            if not (os.path.exists(calib_path) and img_paths):
                print(f"ê²½ê³ : {view}_{cam}ì˜ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ íŒŒì¼ ë˜ëŠ” ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue

            with open(calib_path) as f: calib = json.load(f)
            K, dist = np.array(calib["camera_matrix"]), np.array(calib["distortion_coeffs"])
            
            # ì™œê³¡ ë³´ì •ëœ ì´ë¯¸ì§€ë¥¼ ì‹œê°í™”ì— ì‚¬ìš©
            img_vis = cv2.cvtColor(cv2.undistort(cv2.imread(img_paths[0]), K, dist, None, K), cv2.COLOR_BGR2RGB)

            offset_pos, all_quats = [], []
            for mid, offset in MARKER_OFFSETS[view].items():
                if mid not in poses: continue
                
                p = poses[mid]
                tvec = np.array([p["position_m"][k] for k in 'xyz'])
                quat = np.array([p["rotation_quat"][k] for k in 'xyzw'])
                
                # ì˜¤í”„ì…‹ì„ ì ìš©í•˜ì—¬ ê°ì²´ì˜ ì›ì  ìœ„ì¹˜ ì¶”ì •
                offset_pos.append(tvec + R.from_quat(quat).as_matrix() @ offset)
                all_quats.append(quat)
                
                # ê°œë³„ ë§ˆì»¤ì˜ ì¢Œí‘œì¶• ê·¸ë¦¬ê¸°
                rvec = R.from_quat(quat).as_rotvec()
                cv2.drawFrameAxes(img_vis, K, None, rvec, tvec, 0.03) # ì™œê³¡ ë³´ì •ëœ ì´ë¯¸ì§€ì´ë¯€ë¡œ dist=None
                proj_pt, _ = cv2.projectPoints(tvec.reshape(1,3), np.zeros(3), np.zeros(3), K, None)
                cv2.putText(img_vis, f"ID:{mid}", tuple(proj_pt.ravel().astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)
            
            if len(offset_pos) < 2: 
                print(f"ê²½ê³ : {view}_{cam}ì—ì„œ ìœ íš¨ ë§ˆì»¤ê°€ ë¶€ì¡±í•˜ì—¬ í‰ê·  í¬ì¦ˆë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            # ì—¬ëŸ¬ ë§ˆì»¤ì—ì„œ ì¶”ì •ëœ ê°ì²´ ìœ„ì¹˜ì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°
            mean_pos = average_position(np.array(offset_pos))
            std_pos = np.std(offset_pos, axis=0)
            
            # ëª¨ë“  ì¿¼í„°ë‹ˆì–¸ì„ í‰ê· ë‚´ì–´ ê°ì²´ì˜ í‰ê·  ë°©í–¥ ê³„ì‚°
            mean_quat = average_quaternion(np.array(all_quats))
            mean_rvec = R.from_quat(mean_quat).as_rotvec()
            
            # í‰ê·  í¬ì¦ˆ ì¢Œí‘œì¶• ê·¸ë¦¬ê¸° (ë” í¬ê³  êµµê²Œ)
            cv2.drawFrameAxes(img_vis, K, None, mean_rvec, mean_pos, 0.08, 4)
            mean_proj, _ = cv2.projectPoints(mean_pos.reshape(1,3), np.zeros(3), np.zeros(3), K, None)
            xm, ym = mean_proj.ravel().astype(int)
            cv2.drawMarker(img_vis, (xm, ym), (0, 255, 0), cv2.MARKER_CROSS, 25, 3)

            final_summary.append({
                "view": view, "cam": cam, "mean_x_m": mean_pos[0], "mean_y_m": mean_pos[1], "mean_z_m": mean_pos[2],
                "std_x_mm": std_pos[0]*1000, "std_y_mm": std_pos[1]*1000, "std_z_mm": std_pos[2]*1000,
                "rvec_x_deg": np.rad2deg(mean_rvec)[0], "rvec_y_deg": np.rad2deg(mean_rvec)[1], "rvec_z_deg": np.rad2deg(mean_rvec)[2]
            })
            
            plt.figure(figsize=(12, 9)); plt.imshow(img_vis)
            plt.title(f"Final Mean Pose ({view.upper()}-{cam}) | Pos Std (mm): {std_pos[0]*1000:.1f}, {std_pos[1]*1000:.1f}, {std_pos[2]*1000:.1f}", fontsize=14)
            plt.axis('off'); plt.tight_layout()
            
            output_path = os.path.join(RESULT_IMAGE_DIR, f"{view}_{cam}_final_pose.png")
            plt.savefig(output_path); plt.close()
            print(f"ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {output_path}")

    df = pd.DataFrame(final_summary)
    if not df.empty:
        df.to_json(FINAL_SUMMARY_OUTPUT_PATH, orient="records", indent=4)
        print(f"\n--- STAGE 3 ì™„ë£Œ ---")
        print(f"ìµœì¢… ìš”ì•½ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {FINAL_SUMMARY_OUTPUT_PATH}")
        print("--- ìµœì¢… ìš”ì•½ ê²°ê³¼ ---")
        print(df)
    else:
        print("\n--- STAGE 3 ì™„ë£Œ ---")
        print("ì²˜ë¦¬í•  ìœ íš¨ ë°ì´í„°ê°€ ì—†ì–´ ìš”ì•½ íŒŒì¼ì„ ìƒì„±í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# =================================================================================
# â–¶ï¸ ë©”ì¸ ì‹¤í–‰ ë¸”ë¡ (Main Execution Block)
# =================================================================================
if __name__ == "__main__":
    extract_camera_calibration()
    corrected_data = stage1_average_raw_data()
    recalculated_data = stage2_recalculate_pose_from_corners(corrected_data)
    stage3_visualize_and_summarize(recalculated_data)
    print("\nğŸ‰ --- ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. --- ğŸ‰")