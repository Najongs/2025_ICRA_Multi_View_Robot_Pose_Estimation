import os
import glob
import json
import numpy as np
import random
import time
import wandb

import torch
import torch.nn as nn
from torch.utils.data import DataLoader, random_split
from torch.optim.lr_scheduler import CosineAnnealingLR
import timm
from torchvision import transforms
from tqdm import tqdm
import matplotlib.pyplot as plt

# ë‹¤ë¥¸ ëª¨ë“ˆì—ì„œ í´ë˜ìŠ¤ì™€ í•¨ìˆ˜ ì„í¬íŠ¸
from dataset import RobotPoseDataset
from models import DINOv2PoseEstimator
from visualize import visualize_dataset_sample, visualize_predictions

# ==============================================================================
# 2. í•™ìŠµ í™˜ê²½ ì„¤ì • í•¨ìˆ˜
# ==============================================================================

def setup(hyperparameters, dataset_pairs):
    """í•™ìŠµì— í•„ìš”í•œ ëª¨ë“  êµ¬ì„± ìš”ì†Œë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤."""
    print("--- Setting up the environment ---")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # 1. Transform ì •ì˜
    model_name = hyperparameters['model_name']
    dino_model_for_config = timm.create_model(model_name, pretrained=True)
    config = dino_model_for_config.default_cfg
    transform = transforms.Compose([
        transforms.Resize(config['input_size'][-2:]),
        transforms.ToTensor(),
        transforms.Normalize(mean=config['mean'], std=config['std'])
    ])
    print(f"Image transform created for input size: {config['input_size'][-2:]}")

    # 2. Dataset ë° DataLoader ì¤€ë¹„
    full_dataset = RobotPoseDataset(pairs=dataset_pairs, transform=transform, sigma=hyperparameters['heatmap_sigma'])
    val_split = hyperparameters['val_split']
    val_size = int(len(full_dataset) * val_split)
    train_size = len(full_dataset) - val_size
    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])
    
    batch_size = hyperparameters['batch_size']
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)
    print(f"Dataset split: {len(train_dataset)} training samples, {len(val_dataset)} validation samples.")

    # 3. ëª¨ë¸, ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì €, ìŠ¤ì¼€ì¤„ëŸ¬ ì¤€ë¹„
    model = DINOv2PoseEstimator(model_name)
    for param in model.backbone.parameters():
        param.requires_grad = False
    
    if torch.cuda.device_count() > 1:
        print(f"Let's use {torch.cuda.device_count()} GPUs!")
        model = nn.DataParallel(model)
    model.to(device)
        
    crit_kpt = nn.MSEloss()
    crit_ang = nn.SmoothL1Loss(beta=1.0)

    model_to_access = model.module if isinstance(model, nn.DataParallel) else model
    optimizer_kpt = torch.optim.AdamW(model_to_access.keypoint_head.parameters(), lr=hyperparameters['lr_kpt'])
    optimizer_ang = torch.optim.AdamW(model_to_access.angle_head.parameters(), lr=hyperparameters['lr_ang'])

    num_epochs = hyperparameters['num_epochs']
    scheduler_kpt = CosineAnnealingLR(optimizer_kpt, T_max=num_epochs, eta_min=1e-6)
    scheduler_ang = CosineAnnealingLR(optimizer_ang, T_max=num_epochs, eta_min=1e-6)
    
    print(f"Model, losses, and optimizers are ready. Using device: {device}")
    
    return model, train_loader, val_loader, crit_kpt, crit_ang, optimizer_kpt, optimizer_ang, scheduler_kpt, scheduler_ang, device, config

# ==============================================================================
# 3. í•™ìŠµ ë° ê²€ì¦ ë£¨í”„
# ==============================================================================

def train_one_epoch(model, loader, optimizer_kpt, optimizer_ang, crit_kpt, crit_ang, device, loss_weight_kpt, epoch_num):
    model.train()
    total_loss_kpt, total_loss_ang = 0, 0
    loop = tqdm(loader, desc=f"Epoch {epoch_num} [Train]")
    
    for images, heatmaps, angles in loop:
        images, heatmaps, angles = images.to(device), heatmaps.to(device), angles.to(device)
        pred_heatmaps, pred_angles = model(images)
        
        # Keypoint Head ì—…ë°ì´íŠ¸
        optimizer_kpt.zero_grad()
        loss_kpt = crit_kpt(pred_heatmaps, heatmaps) * loss_weight_kpt
        loss_kpt.backward(retain_graph=True) # Angle headì˜ backwardë¥¼ ìœ„í•´ ê·¸ë˜í”„ ìœ ì§€
        optimizer_kpt.step()
        
        # Angle Head ì—…ë°ì´íŠ¸
        optimizer_ang.zero_grad()
        loss_ang = crit_ang(pred_angles, angles)
        loss_ang.backward()
        optimizer_ang.step()
        
        total_loss_kpt += loss_kpt.item()
        total_loss_ang += loss_ang.item()
        loop.set_postfix(loss_kpt=loss_kpt.item(), loss_ang=loss_ang.item())
        
    avg_loss_kpt = total_loss_kpt / len(loader)
    avg_loss_ang = total_loss_ang / len(loader)
    return avg_loss_kpt, avg_loss_ang

def validate(model, loader, crit_kpt, crit_ang, device, loss_weight_kpt, epoch_num):
    model.eval()
    total_loss_kpt, total_loss_ang = 0, 0
    loop = tqdm(loader, desc=f"Epoch {epoch_num} [Validate]", leave=False)
    
    with torch.no_grad():
        for images, heatmaps, angles in loop:
            images, heatmaps, angles = images.to(device), heatmaps.to(device), angles.to(device)
            pred_heatmaps, pred_angles = model(images)
            
            loss_kpt = crit_kpt(pred_heatmaps, heatmaps)
            loss_ang = crit_ang(pred_angles, angles)
            
            total_loss_kpt += loss_kpt.item()
            total_loss_ang += loss_ang.item()
            loop.set_postfix(val_kpt=loss_kpt.item(), val_ang=loss_ang.item())
            
    avg_loss_kpt = total_loss_kpt / len(loader)
    avg_loss_ang = total_loss_ang / len(loader)
    # ê²€ì¦ ì‹œì—ëŠ” ë‘ ì†ì‹¤ì˜ ê°€ì¤‘í•©ì„ ìµœì¢… ì„±ëŠ¥ ì§€í‘œë¡œ ì‚¬ìš©
    avg_total_loss = (avg_loss_kpt * loss_weight_kpt) + avg_loss_ang
    return avg_total_loss, avg_loss_kpt, avg_loss_ang

# ==============================================================================
# 4. ë©”ì¸ ì‹¤í–‰ë¶€
# ==============================================================================

if __name__ == '__main__':
    # --- ë°ì´í„° í˜ì–´ë§ ---
    # ì´ ë¶€ë¶„ì€ dataset.pyì˜ create_dataset_pairs() í•¨ìˆ˜ë¡œ ë¶„ë¦¬í•˜ëŠ” ê²ƒì´ ë” ê¹”ë”í•©ë‹ˆë‹¤.
    # ì—¬ê¸°ì„œëŠ” ìŠ¤í¬ë¦½íŠ¸ì˜ ë…ë¦½ ì‹¤í–‰ì„ ìœ„í•´ í¬í•¨í•©ë‹ˆë‹¤.
    # ... (dataset_pairs ìƒì„± ë¡œì§) ...

    # --- í•˜ì´í¼íŒŒë¼ë¯¸í„° ë° ê²½ë¡œ ì„¤ì • ---
    hyperparameters = {
        'model_name': 'vit_base_patch14_dinov2.lvd142m',
        'batch_size': 150,
        'num_epochs': 100,
        'val_split': 0.1,
        'loss_weight_kpt': 1.0, 
        'lr_kpt': 0.005,
        'lr_ang': 0.005,
        'heatmap_sigma': 2.0
    }
    CHECKPOINT_PATH = 'checkpoint.pth'
    BEST_MODEL_PATH = 'best_pose_estimator_model.pth'

    # --- W&B ì´ˆê¸°í™” ---
    run = wandb.init(project="robot-pose-estimation", config=hyperparameters)
    
    # --- í•™ìŠµ í™˜ê²½ ì„¤ì • ---
    model, train_loader, val_loader, crit_kpt, crit_ang, optimizer_kpt, optimizer_ang, scheduler_kpt, scheduler_ang, device, config = setup(
        hyperparameters, dataset_pairs
    )
    wandb.watch(model, log="all", log_freq=100)
    
    # --- ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ---
    start_epoch = 0
    best_val_loss = float('inf')
    if os.path.exists(CHECKPOINT_PATH):
        print(f"âœ… Resuming training from '{CHECKPOINT_PATH}'.")
        checkpoint = torch.load(CHECKPOINT_PATH, map_location='cpu')
        model_to_load = model.module if isinstance(model, nn.DataParallel) else model
        model_to_load.load_state_dict(checkpoint['model_state_dict'])
        optimizer_kpt.load_state_dict(checkpoint['optimizer_kpt_state_dict'])
        optimizer_ang.load_state_dict(checkpoint['optimizer_ang_state_dict'])
        scheduler_kpt.load_state_dict(checkpoint['scheduler_kpt_state_dict'])
        scheduler_ang.load_state_dict(checkpoint['scheduler_ang_state_dict'])
        start_epoch = checkpoint['epoch']
        best_val_loss = checkpoint['best_val_loss']
        print(f"   -> Resumed from epoch {start_epoch}, with best validation loss: {best_val_loss:.6f}")
    else:
        print("â„¹ï¸ No checkpoint found. Starting training from scratch.")

    # --- í•™ìŠµ ì „ ë°ì´í„° ì‹œê°í™” ---
    visualize_dataset_sample(train_loader.dataset.dataset, config, num_samples=3)

    # --- í•™ìŠµ ì‹œì‘ ---
    print("\n--- Starting Training ---")
    for epoch in range(start_epoch, hyperparameters['num_epochs']):
        train_loss_kpt, train_loss_ang = train_one_epoch(
            model, train_loader, optimizer_kpt, optimizer_ang, crit_kpt, crit_ang, device, 
            loss_weight_kpt=hyperparameters['loss_weight_kpt'], epoch_num=epoch+1
        )
        val_loss, val_loss_kpt, val_loss_ang = validate(
            model, val_loader, crit_kpt, crit_ang, device, 
            loss_weight_kpt=hyperparameters['loss_weight_kpt'], epoch_num=epoch+1
        )
        
        scheduler_kpt.step()
        scheduler_ang.step()

        current_lr_kpt = optimizer_kpt.param_groups[0]['lr']
        current_lr_ang = optimizer_ang.param_groups[0]['lr']
        
        print(f"Epoch {epoch+1}/{hyperparameters['num_epochs']} Summary -> Train [Kpt: {train_loss_kpt:.6f}, Ang: {train_loss_ang:.6f}], Val [Total: {val_loss:.6f}, Kpt: {val_loss_kpt:.6f}, Ang: {val_loss_ang:.6f}]")
        print(f"  -> LRs [Kpt: {current_lr_kpt:.6f}, Ang: {current_lr_ang:.6f}]")
        
        # W&B ë¡œê¹…
        wandb.log({
            "epoch": epoch + 1,
            "train_loss_kpt": train_loss_kpt,
            "train_loss_ang": train_loss_ang,
            "val_loss_total": val_loss,
            "val_loss_kpt": val_loss_kpt,
            "val_loss_ang": val_loss_ang,
            "lr_kpt": current_lr_kpt,
            "lr_ang": current_lr_ang
        })

        # ì²´í¬í¬ì¸íŠ¸ ë° ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
        state_to_save = model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict()
        checkpoint = {
            'epoch': epoch + 1, 'model_state_dict': state_to_save,
            'optimizer_kpt_state_dict': optimizer_kpt.state_dict(),
            'optimizer_ang_state_dict': optimizer_ang.state_dict(),
            'scheduler_kpt_state_dict': scheduler_kpt.state_dict(),
            'scheduler_ang_state_dict': scheduler_ang.state_dict(),
            'best_val_loss': best_val_loss,
        }
        torch.save(checkpoint, CHECKPOINT_PATH)
        
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(state_to_save, BEST_MODEL_PATH)
            print(f"  -> ğŸ‰ New best model saved with validation loss: {best_val_loss:.6f}")
            prediction_fig = visualize_predictions(
                model, val_loader.dataset, device, config, epoch_num=epoch + 1, num_samples=3
            )
            wandb.log({"validation_predictions": wandb.Image(prediction_fig)})
            plt.close(prediction_fig)

    print("\n--- Training Finished ---")
    print(f"ğŸ† Best validation loss: {best_val_loss:.6f}")
    
    run.finish()